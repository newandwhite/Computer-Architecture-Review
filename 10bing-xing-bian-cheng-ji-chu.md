# 10 并行编程基础
### 程序的并行行为
* **指令并行**：指令之间的并行执行，当指令间不存在相关时，这些指令可以在处理器流水线上重叠起来并行执行
    * 指令相关：
        * 数据相关
            * 写后读RAW：存在真正的数据传递关系
            * 读后写WAR
            * 写后写WAW
        * 控制相关：存在分支指令，一条指令的执行取决于该分支指令的执行结果
        * 结构相关：两条指令同时需要流水线中同一个功能部件
    
    多种微结构：指令流水线、多发射、动态调度、寄存器重命名、转移猜测等
* **数据并行**：对集合或集合中的数组元素同时执行相同操作（通常来源于循环语句）
* **任务并行**（多线程、多进程）：将不同的任务分布到不同的处理单元上执行

### 并行编程模型
* ~~单任务数据并行模型（略）~~
* 多任务**共享存储**编程模型：运行在各处理器上的进程（或线程）可以通过读/写共享存储器中的共享变量来相互通信
* 多任务**消息传递**编程模型：在不同处理器节点上运行的进程均有独立的地址空间，可以通过网络传递消息而相互通信
    * 多进程
    * 异步并行性：各进程彼此异步执行，使用栅障和阻塞通信方式同步进程
    * 独立地址空间
    * 显式相互作用
    * 显式分配

### 典型的并行编程环境
* SIMD编程：单指令多数据流并行
    * 一条SIMD指令可以同时对一组数据进行相同的计算
* Posix编程环境（Pthread）
* OpenMP编程环境：基于线程的并行编程模型，开始于一个单独的主线程，主线程串行执行，遇到一个并行域开始并行执行，然后fork、join
    * 使用制导语句实现并行（前缀为#pragma omp）
* MPI编程环境：计算由一个或多个调用库函数进行消息收/发的进程所组成。大多数时候，一组固定的进程在程序初始化时生成，在一个处理器核上通常只生成一个进程
    * 特点
        * 高可移植性
        * 易用性
        * 对运行的硬件要求简单
    * 集体通信：栅障、广播、收集、散播、归约
        * 不需要同步操作就能同步进程，会造成死锁
    * 通信域：提供MPI中独立的安全消息传递
        * 进程组
        * 上下文
    * 点对点通信
        * 阻塞
        * 非阻塞